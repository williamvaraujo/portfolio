{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8320c815",
   "metadata": {},
   "source": [
    "# **Automação Webscraping Portfólio**\n",
    "\n",
    "Bibliotecas necessárias a serem instaladas no Anaconda:\n",
    "\\n-Selenium\n",
    "\\n-Webdriver-manager\n",
    "\\n-Beautifulsoup bs4\n",
    "\\n-Requests\n",
    "\\n-Scrapy\n",
    "\n",
    "Aplicativo\n",
    "Webdriver manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9bbc51d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T21:06:59.443885Z",
     "start_time": "2022-12-01T21:06:26.618715Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: urllib3 in c:\\programdata\\anaconda3\\lib\\site-packages (1.26.11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Downloading: 100%|████████████████████████████████████████████████████████| 6.46M/6.46M [00:00<00:00, 10.6MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escreva o nome do autor: William Araújo\n",
      "Digite o site: nortelivre.com.br\n",
      "Podemos continuar, mas a página não tem protocolo de segurança https\n",
      "O site atual é https://nortelivre.com.br/author/contatonortelivre/\n"
     ]
    }
   ],
   "source": [
    "#1 - Importar as bibliotecas Selenium e Webdriver\n",
    "!pip install urllib3\n",
    "from selenium import webdriver #esta biblioteca serve para comandar o navegador por meio de um bot\n",
    "from webdriver_manager.chrome import ChromeDriverManager #esta biblioteca serve para atualizar o controlador do navegador\n",
    "from selenium.webdriver.chrome.service import Service #esta biblioteca serve para atualizar o serviço automaticamente\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "#import pytime\n",
    "\n",
    "#2 - Criando um atualizador automático do ChromeDriver\n",
    "servico = Service(ChromeDriverManager().install())\n",
    "navegador = webdriver.Chrome(service=servico)\n",
    "\n",
    "#3 - Controlando o Python para abrir o Chrome e colocar o nome do autor\n",
    "# e o site e acessar automaticamente\n",
    "navegador.get('http://www.google.com.br')\n",
    "nome_autor = input('Escreva o nome do autor: ')\n",
    "nome_para_pesquisa = f'\"{nome_autor}\"'\n",
    "site_do_autor = input ('Digite o site: ')\n",
    "site_para_pesquisa = f' site:{site_do_autor}'\n",
    "pesquisa = {}\n",
    "pesquisa['nome'] = nome_para_pesquisa\n",
    "pesquisa['site'] = site_para_pesquisa\n",
    "navegador.find_element(\n",
    "    'xpath','/html/body/div[1]/div[3]/form/div[1]/div[1]/div[1]/div/div[2]/input').send_keys(pesquisa['nome'],pesquisa['site'])\n",
    "navegador.find_element(\n",
    "    'xpath','/html/body/div[1]/div[3]/form/div[1]/div[1]/div[4]/center/input[2]').click()\n",
    "\n",
    "#condição de sites sem https\n",
    "if  navegador.find_element('xpath','/html/body/div/div[2]/button[3]'):\n",
    "    navegador.find_element(\n",
    "    'xpath','/html/body/div/div[2]/button[3]').click()\n",
    "    navegador.find_element(\n",
    "    'xpath','//*[@id=\"proceed-link\"]').click() \n",
    "    site_url = navegador.current_url\n",
    "    print('Podemos continuar, mas a página não tem protocolo de segurança https')\n",
    "    print(f'O site atual é {site_url}')\n",
    "    \n",
    "#    time.sleep(3)\n",
    "#    print('Podemos continuar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "7cc406ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T01:26:22.126223Z",
     "start_time": "2022-11-26T01:26:19.933332Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'nortelivre.com.br'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#4 - Importar o HTML da página on-line\n",
    "import requests #esta biblioteca serve para importar o código html de uma página\n",
    "\n",
    "from urllib3.exceptions import InsecureRequestWarning #estas bibliotecas servem para ajudar a verificar sites inseguros\n",
    "from urllib3 import disable_warnings\n",
    "site_url = navegador.current_url\n",
    "site = requests.get(site_url, verify=False).content\n",
    "#print(site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "221ef8f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T01:26:22.327810Z",
     "start_time": "2022-11-26T01:26:22.309831Z"
    }
   },
   "outputs": [],
   "source": [
    "#5 - Extrair dados específicos do HTML e montando um dicionário de portfolio\n",
    "from bs4 import BeautifulSoup #esta biblioteca serve para extrair coisas específicas de um código html\n",
    "\n",
    "#criando em branco dicionário e listas que armazenarão os dados\n",
    "portfolio = {}\n",
    "lista_datas = []\n",
    "lista_titulos = []\n",
    "#lista_resumos = []\n",
    "lista_links = []\n",
    "lista_imagens = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "107d653b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T01:26:55.346991Z",
     "start_time": "2022-11-26T01:26:24.911068Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'nortelivre.com.br'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'nortelivre.com.br'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'nortelivre.com.br'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'nortelivre.com.br'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'nortelivre.com.br'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#6 - Selenium e Web Driver irão para a próxima página\n",
    "import pandas as pd #biblioteca responsável por organizar o dados vindos do dicionário\n",
    "\n",
    "while BeautifulSoup(site,'html.parser').select('[aria-label=\"next-page\"]'):\n",
    "       #datas\n",
    "    datas_materias = BeautifulSoup(site,'html.parser').select('time',{'class':'entry-date updated td-module-date'})\n",
    "    for datas in datas_materias:\n",
    "        lista_datas.append(datas.get_text())\n",
    "    portfolio['datas'] = lista_datas\n",
    "    #print(portfolio)\n",
    "#        \n",
    "       #titulos\n",
    "    titulos_materias = BeautifulSoup(site,'html.parser').select('h3',{'class':'entry-title td-module-title'})\n",
    "    for titulos in titulos_materias:\n",
    "        lista_titulos.append(titulos.get_text())\n",
    "    portfolio['titulos'] = lista_titulos\n",
    "    #print(portfolio)\n",
    "#        \n",
    "       #Resumos\n",
    "    #resumos_materias = BeautifulSoup(site, 'html.parser').select('.post-box .post-excerpt')\n",
    "    #for resumos in resumos_materias:\n",
    "    #    lista_resumos.append(resumos.get_text())\n",
    "    #portfolio['resumos'] = lista_resumos\n",
    "    #print(portfolio)\n",
    "#        \n",
    "       #links\n",
    "    links_materias = BeautifulSoup(site, 'html.parser').select('h3>a')\n",
    "    for links in links_materias:\n",
    "        lista_links.append(links.get('href'))\n",
    "    portfolio['links'] = lista_links\n",
    "    #print(portfolio)\n",
    "#        \n",
    "       #imagens\n",
    "    #imagens_materias = BeautifulSoup(site,'html.parser').select('a>img.entry-thumb')\n",
    "    #for imagens in imagens_materias:\n",
    "    #    lista_imagens.append(imagens.get('data-src-img'))\n",
    "    #portfolio['imagens'] = lista_imagens\n",
    "    #print(portfolio)\n",
    "#        \n",
    "       #indo para próxima página e atualizando o html do scrap\n",
    "    navegador.execute_script('window.scrollBy(0,1500)')\n",
    "    navegador.find_element(By.CSS_SELECTOR,'[aria-label=\"next-page\"]').click()\n",
    "    site_atual = navegador.current_url\n",
    "    site = requests.get(site_atual, verify=False).text\n",
    "    time.sleep(1)\n",
    "#class=\"td-icon-menu-right\n",
    "#'_class_name','.page-nav a').click()\n",
    "#.page-nav a, .page-nav span      \n",
    "\n",
    "\n",
    "\n",
    "else:\n",
    "\n",
    "       #datas\n",
    "    datas_materias = BeautifulSoup(site,'html.parser').select('time',{'class':'entry-date updated td-module-date'})\n",
    "    for datas in datas_materias:\n",
    "        lista_datas.append(datas.get_text())\n",
    "    portfolio['datas'] = lista_datas\n",
    "#        \n",
    "       #titulos\n",
    "    titulos_materias = BeautifulSoup(site,'html.parser').select('h3',{'class':'entry-title td-module-title'})\n",
    "    for titulos in titulos_materias:\n",
    "        lista_titulos.append(titulos.get_text())\n",
    "    portfolio['titulos'] = lista_titulos\n",
    "    #print(portfolio)\n",
    "#        \n",
    "       #Resumos\n",
    "    #resumos_materias = BeautifulSoup(site, 'html.parser').select('.post-box .post-excerpt')\n",
    "    #for resumos in resumos_materias:\n",
    "    #    lista_resumos.append(resumos.get_text())\n",
    "    #portfolio['resumos'] = lista_resumos\n",
    "    #print(portfolio)\n",
    "#        \n",
    "       #links\n",
    "    links_materias = BeautifulSoup(site, 'html.parser').select('h3>a')\n",
    "    for links in links_materias:\n",
    "        lista_links.append(links.get('href'))\n",
    "    portfolio['links'] = lista_links\n",
    "    #print(portfolio)\n",
    "#        \n",
    "       #imagens\n",
    "    #imagens_materias = BeautifulSoup(site,'html.parser').select('.td-module-thumb .entry-thumb')\n",
    "    #for imagens in imagens_materias:\n",
    "    #    lista_imagens.append(imagens.get('src'))\n",
    "    #portfolio['imagens'] = lista_imagens\n",
    "    #print(portfolio)\n",
    "#\n",
    "    tabela_portfolio = pd.DataFrame.from_dict(portfolio, orient='index').transpose()\n",
    "tabela_portfolio\n",
    "tabela_portfolio.to_csv('nortelivre.csv')\n",
    "#break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ca5c09",
   "metadata": {},
   "source": [
    "Guardando esta informação apenas para ter um gabarito do que mais causou problemas/n\n",
    "#navegador.find_element(By.XPATH,'//a[contains(@aria-label,\"next-page\")]').click()/n\n",
    "#navegador.find_element(By.CSS_SELECTOR,'[aria-label=\"next-page\"]').click()\n",
    "\n",
    "https://stackoverflow.com/questions/40442014/python-pandas-valueerror-arrays-must-be-all-same-length"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
